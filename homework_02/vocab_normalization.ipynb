{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# ... file : vocabulary_size_normalization.py\n",
    "#\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ...\n",
    "# ... msds 7337 NLP\n",
    "# ... homework 02\n",
    "# ... gutenberg - documment vocabulary normalization\n",
    "# ... pmcdevitt@smu.edu\n",
    "# ... 15-sep-2018\n",
    "# ...\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... load packages\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "plt.rc('xtick', labelsize=20)     \n",
    "plt.rc('ytick', labelsize=20)\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... some directory and file name definitions\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "files = \".*\\.txt\"\n",
    "home_dir = \"/home/mcdevitt/_ds/_smu/_src/nlp/homework_02/\"\n",
    "corpus_root = \"./text/\"\n",
    "plot_dir = \"./plots/\"\n",
    "\n",
    "os.chdir(home_dir)\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... lexical diversity score - as given in nltk site\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "def lexical_diversity(my_text_data):\n",
    "    tokens = len(my_text_data)\n",
    "    types = len(set(my_text_data))\n",
    "    diversity_score = types / tokens\n",
    "    return diversity_score\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... read in texts / assemble corpus for evaluation\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "readers = PlaintextCorpusReader(corpus_root, files)\n",
    "\n",
    "files = readers.fileids()\n",
    "files[0:10]\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... create table to accumulate summary data\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "results_tbl = pd.DataFrame(columns =\n",
    "    ['text_name',\n",
    "     'num_chars',\n",
    "     'num_words',\n",
    "     'num_sents',\n",
    "     'num_vocab',\n",
    "     'tokens',\n",
    "     'types',\n",
    "     'lex_div'])\n",
    "\n",
    "i_index = []\n",
    "i_index = 0\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... loop thru each text to assemble metrics\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "print(\"Some basic statistics\\n\")\n",
    "\n",
    "for fileid in readers.fileids():\n",
    "    \n",
    "    print(i_index, \"---\", fileid)\n",
    "    \n",
    "    num_chars = len(readers.raw(fileid))\n",
    "    num_words = len(readers.words(fileid))\n",
    "    num_sents = len(readers.sents(fileid))\n",
    "    tokens = len(readers.words(fileid))\n",
    "    types = len(set(readers.words(fileid)))\n",
    "    \n",
    "    num_vocab = len(set(w.lower() for w in readers.words(fileid)))\n",
    "\n",
    "    rtxt = readers.words(fileid)\n",
    "    ldiv = lexical_diversity(rtxt)\n",
    "\n",
    "    table_data = {\n",
    "     'text_name' : fileid,\n",
    "     'num_chars' : num_chars,\n",
    "     'num_words' : num_words,\n",
    "     'num_sents' : num_sents,\n",
    "     'num_vocab' : num_vocab,\n",
    "     'tokens' : tokens,\n",
    "     'types' : types,\n",
    "     'lex_div' : ldiv\n",
    "    } \n",
    "\n",
    "    df_tbl = pd.DataFrame(table_data,\n",
    "        columns = ['text_name',\n",
    "             'num_chars',\n",
    "             'num_words',\n",
    "             'num_sents',\n",
    "             'num_vocab',\n",
    "             'tokens',\n",
    "             'types',\n",
    "             'lex_div'],\n",
    "    index = [i_index + 1])\n",
    "    i_index += 1\n",
    "    results_tbl = results_tbl.append(df_tbl)\n",
    "    \n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... basic statistics table complete\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "results_tbl = results_tbl.sort_values(results_tbl.columns[4], ascending = False)\n",
    "print('Results_tbl - sorted by col num_vocab')\n",
    "results_tbl\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... normalize each column by max column value\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "results_nrmlzd = results_tbl.copy()\n",
    "results_nrmlzd = results_nrmlzd.sort_values(results_nrmlzd.columns[4], ascending = False)\n",
    "\n",
    "df = results_nrmlzd.iloc[:, 1:8]\n",
    "df_nrml = df / df.max()\n",
    "\n",
    "df_labels = results_nrmlzd.iloc[:, 0]\n",
    "\n",
    "results_nrmlzd = pd.concat([df_labels, df_nrml], axis = 1)\n",
    "\n",
    "results_nrmlzd['vocab_ldiv'] = results_nrmlzd.apply(lambda x: x.lex_div * (x.num_words), axis=1)\n",
    "results_nrmlzd['vocab_ldiv'] = results_nrmlzd['vocab_ldiv'] / results_nrmlzd['vocab_ldiv'].max()\n",
    "\n",
    "print('results_nrmlzd - ')\n",
    "\n",
    "results_nrmlzd = results_nrmlzd.sort_values(results_nrmlzd.columns[4], ascending = False)\n",
    "print('results_nrmlzd - sorted by col num_vocab')\n",
    "results_nrmlzd\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... add some shorter title names to fit within plotting space\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "results_tbl['title_short'] = [txt[:25] for txt in results_tbl['text_name']]\n",
    "results_tbl['title_short'][:5]\n",
    "\n",
    "results_nrmlzd['title_short'] = [txt[:25] for txt in results_nrmlzd['text_name']]\n",
    "results_nrmlzd['title_short'][:5]\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... plot - vocabulary normalized size - sorted in descending order\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "N = len(results_nrmlzd)\n",
    "\n",
    "ind = np.arange(N) \n",
    "width = 0.5\n",
    "\n",
    "_ = plt.figure(figsize = (18, 12))\n",
    "offset = 0\n",
    "_ = plt.bar(ind + offset, results_nrmlzd['num_vocab'], width, label='Vocab', color = 'orchid')\n",
    "\n",
    "_ = plt.xticks(ind + width / 2, results_nrmlzd['title_short'], fontsize = '15')\n",
    "_ = plt.xticks(rotation=90, )\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.title('Vocabulary Size Normalized - 100+ Childrens Books', fontsize = '30')\n",
    "\n",
    "axes = plt.gca()\n",
    "_ = plt.savefig(plot_dir + 'childrens_books_normalized_vocab.png')\n",
    "_ = plt.show()\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... write table to output file for future reference\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "os.chdir(home_dir)\n",
    "\n",
    "file_name = \"vocab_normalized.txt\"\n",
    "\n",
    "results_nrmlzd.to_csv(file_name,\n",
    "                      header = True,\n",
    "                      index = None,\n",
    "                      sep=',',\n",
    "                      mode = 'a')\n",
    "    \n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... end_of_file\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
