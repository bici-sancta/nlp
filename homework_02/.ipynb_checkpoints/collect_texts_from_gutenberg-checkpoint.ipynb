{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7841', '5742', '13539', '7425', '16046']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['http://www.gutenberg.org/cache/epub/7841/pg7841.txt',\n",
       " 'http://www.gutenberg.org/cache/epub/5742/pg5742.txt',\n",
       " 'http://www.gutenberg.org/cache/epub/13539/pg13539.txt',\n",
       " 'http://www.gutenberg.org/cache/epub/7425/pg7425.txt',\n",
       " 'http://www.gutenberg.org/cache/epub/16046/pg16046.txt']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['A Primary Reader: \\nOld-time Stories, Fairy Tales and Myths Retold by Children',\n",
       " 'The Bird-Woman of the Lewis and Clark Expedition',\n",
       " \"Dr. Scudder's Tales for Little Readers, About the Heathen.\",\n",
       " 'The Louisa Alcott Reader: a Supplementary Reader for the Fourth Year of School',\n",
       " 'Boy Blue and his friends, School ed.']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a_primary_reader:_old-time_stories,_fairy_tales_and_myths_retold_by_children',\n",
       " 'the_bird-woman_of_the_lewis_and_clark_expedition',\n",
       " \"dr._scudder's_tales_for_little_readers,_about_the_heathen.\",\n",
       " 'the_louisa_alcott_reader:_a_supplementary_reader_for_the_fourth_year_of_school',\n",
       " 'boy_blue_and_his_friends,_school_ed.',\n",
       " 'the_book_of_nature_myths',\n",
       " \"the_flag_of_my_country._shikéyah_bidah_na'at'a'í;navajo_new_world_readers_2\",\n",
       " \"chambers's_elementary_science_readers,_book_i\",\n",
       " 'the_little_lame_prince;rewritten_for_young_readers_by_margaret_waters',\n",
       " \"harry's_ladder_to_learning\"]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# ... file : collect_texts_from_gutenberg.py\n",
    "#\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ...\n",
    "# ... msds 7337 NLP\n",
    "# ... homework 02\n",
    "# ... gutenberg - documment vocabulary normalization\n",
    "# ... pmcdevitt@smu.edu\n",
    "# ... 15-sep-2018\n",
    "# ...\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... load packages\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import strip\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... some plotting defaults\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "plt.rc('xtick', labelsize=20)     \n",
    "plt.rc('ytick', labelsize=20)\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... declare some directory locations\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "home_dir = \"/home/mcdevitt/_ds/_smu/_src/nlp/homework_02/\"\n",
    "corpus_dir = \"./text/\"\n",
    "plot_dir = \"./plots/\"\n",
    "\n",
    "os.chdir(home_dir)\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... extract urls for targeted texts \n",
    "# ...\n",
    "# ... if link is in this format : //www.gutenberg.org/ebooks/7841\n",
    "# ... then texts is at this corresponding url : http://www.gutenberg.org/cache/epub/14880/pg14880.txt\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "page = requests.get('http://www.gutenberg.org/wiki/Children%27s_Instructional_Books_(Bookshelf)')\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "links = tree.xpath('//a/@href')\n",
    "\n",
    "book_link_mask = 'gutenberg.org/ebooks/'\n",
    "book_links = [s for s in links if book_link_mask.lower() in s.lower()]\n",
    "book_links = [lnk.replace('ebooks', 'cache/epub') for lnk in book_links]\n",
    "\n",
    "# ... extract page number from end of url\n",
    "\n",
    "pg_num = [lnk.split(\"epub/\",1)[1] for lnk in book_links]\n",
    "pg_num[0:5]\n",
    "\n",
    "# ... recombine to create full url\n",
    "\n",
    "text_link = ['http:' + lnk + '/pg' + pg + '.txt' for lnk,pg in zip(book_links, pg_num)]\n",
    "text_link[0:5]\n",
    "\n",
    "len(text_link)\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... extract book titles \n",
    "# ... tree.xpath('//div[@title=\"buyer-name\"]/text()')\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "title = []\n",
    "\n",
    "for ib in range(0, len(pg_num)) :\n",
    "    path = '//a[@title=\"ebook:' + pg_num[ib] + '\"]/text()'\n",
    "    nxt_title = tree.xpath(path)[0]\n",
    "    title.append(nxt_title)\n",
    "\n",
    "title[0:5]\n",
    "len(title)\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... clean up titles so filenames have standard chars and no spaces\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "''.join([x if x in string.printable else '' for x in title])\n",
    "\n",
    "title = [x.replace('\\n', '') for x in title]\n",
    "title = [x.replace(' ', '_') for x in title]\n",
    "title = [x.lower() for x in title]\n",
    "\n",
    "title[0:10]\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... download texts to local directory\n",
    "# ... capture errors to identify special case urls\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "import wget\n",
    "\n",
    "print('Beginning file downloads ...')\n",
    "\n",
    "os.chdir(home_dir)\n",
    "os.chdir(corpus_dir)\n",
    "\n",
    "error_indx = []\n",
    "pipe = ' | '\n",
    "\n",
    "for ib in range(0, len(pg_num)) : \n",
    "    \n",
    "    url = text_link[ib]\n",
    "    file_name = title[ib] + '.txt'\n",
    "    \n",
    "    try :\n",
    "        wget.download(url, file_name)\n",
    "        \n",
    "    except HTTPError as e:\n",
    "        print (\"HTTP error({0}): {1}\".format(e.errno, e.strerror))\n",
    "        error_indx.append(str(ib) + pipe + pg_num[ib] + pipe + title[ib])\n",
    "        \n",
    "        try :\n",
    "            fix_url = text_link[ib].replace('.txt', '-0.txt')\n",
    "            fix_url = fix.replace('/pg', '/')\n",
    "            fix_url = fix.replace('/cache/epub/', '/files/')\n",
    "            print(fix_url)\n",
    "            wget.download(fix_url, file_name)\n",
    "            \n",
    "        except :\n",
    "            print ('attempted fix_url did not resolve error')\n",
    "            \n",
    "print('... file downloads complete.')\n",
    "\n",
    "error_indx\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "# ... end_of_file\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
